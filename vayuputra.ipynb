{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EugNr2ig5ziZ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "def extract_frames(video_path, output_dir, frequency=10):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    # Make sure we successfully opened the video\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video at {video_path}\")\n",
        "        return []\n",
        "\n",
        "    frames = []\n",
        "    count = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if count % frequency == 0:\n",
        "            frames.append(frame)  # Store frame in memory\n",
        "\n",
        "        count += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Extracted {len(frames)} frames\")\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zb00Jv0u9rwv"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image):\n",
        "    \"\"\"\n",
        "    Enhance image for better feature detection\n",
        "\n",
        "    Args:\n",
        "        image: Input image\n",
        "    Returns:\n",
        "        Processed image\n",
        "    \"\"\"\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply histogram equalization for better contrast\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    equalized = clahe.apply(gray)\n",
        "\n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(equalized, (5, 5), 0)\n",
        "\n",
        "    return blurred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luu5HJyEAE5o"
      },
      "source": [
        "Image Stitching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3Kx_ldXA-TPH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def detect_and_match_features(img1, img2):\n",
        "    \"\"\"\n",
        "    Detect and match features between two images\n",
        "\n",
        "    Args:\n",
        "        img1, img2: Input images\n",
        "    Returns:\n",
        "        Matching points in both images\n",
        "    \"\"\"\n",
        "    # Initialize ORB detector\n",
        "    orb = cv2.ORB_create(nfeatures=1000)\n",
        "\n",
        "    # Find keypoints and descriptors\n",
        "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
        "    kp2, des2 = orb.detectAndCompute(img2, None)\n",
        "\n",
        "    # Create matcher\n",
        "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "\n",
        "    # Match descriptors\n",
        "    matches = bf.match(des1, des2)\n",
        "\n",
        "    # Sort by distance\n",
        "    matches = sorted(matches, key=lambda x: x.distance)\n",
        "\n",
        "    # Take only good matches\n",
        "    good_matches = matches[:50]\n",
        "\n",
        "    # Extract location of matched keypoints\n",
        "    src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "\n",
        "    return src_pts, dst_pts, good_matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7iwbDnWVBCnO"
      },
      "outputs": [],
      "source": [
        "def compute_homography(src_pts, dst_pts):\n",
        "    \"\"\"\n",
        "    Compute homography matrix between two sets of points\n",
        "\n",
        "    Args:\n",
        "        src_pts, dst_pts: Matching points in two images\n",
        "    Returns:\n",
        "        Homography matrix\n",
        "    \"\"\"\n",
        "    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "    return H, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Nryw-4WpCqso"
      },
      "outputs": [],
      "source": [
        "def stitch_images_custom(images):\n",
        "    # Convert to grayscale for better feature detection\n",
        "    gray_images = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in images]\n",
        "\n",
        "    # Create feature detector\n",
        "    orb = cv2.ORB_create(nfeatures=2000)\n",
        "\n",
        "    # Find keypoints and descriptors\n",
        "    keypoints = []\n",
        "    descriptors = []\n",
        "    for img in gray_images:\n",
        "        kp, des = orb.detectAndCompute(img, None)\n",
        "        keypoints.append(kp)\n",
        "        descriptors.append(des)\n",
        "\n",
        "    # Create matches between consecutive images\n",
        "    matches_list = []\n",
        "    for i in range(len(images)-1):\n",
        "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "        matches = bf.match(descriptors[i], descriptors[i+1])\n",
        "        matches = sorted(matches, key=lambda x: x.distance)\n",
        "        matches_list.append(matches[:100])  # Take top 100 matches\n",
        "\n",
        "    # Print diagnostic information\n",
        "    for i, matches in enumerate(matches_list):\n",
        "        print(f\"Image pair {i}-{i+1}: {len(matches)} good matches\")\n",
        "\n",
        "    # Continue with stitching implementation or use OpenCV's stitcher\n",
        "    stitcher = cv2.Stitcher_create()\n",
        "    status, panorama = stitcher.stitch(images)\n",
        "\n",
        "    if status == cv2.Stitcher_OK:\n",
        "        return panorama\n",
        "    else:\n",
        "        print(f\"Stitching failed with status code: {status}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pEuelQKBrfw"
      },
      "source": [
        "Obstacle detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FKlPt4oPBoDu"
      },
      "outputs": [],
      "source": [
        "def detect_obstacles(image):\n",
        "    \"\"\"\n",
        "    Detect obstacles in terrain image\n",
        "\n",
        "    Args:\n",
        "        image: Input terrain image\n",
        "    Returns:\n",
        "        Binary mask with obstacles marked as white (255)\n",
        "    \"\"\"\n",
        "    # Convert to grayscale if not already\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image\n",
        "\n",
        "    # Apply adaptive thresholding\n",
        "    thresh = cv2.adaptiveThreshold(\n",
        "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY_INV, 11, 2\n",
        "    )\n",
        "\n",
        "    # Detect edges using Canny\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "    # Combine thresholding and edge detection\n",
        "    combined = cv2.bitwise_or(thresh, edges)\n",
        "\n",
        "    # Apply morphological operations to clean up\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    obstacle_mask = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    return obstacle_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zhj-2VclB8nE"
      },
      "outputs": [],
      "source": [
        "def classify_terrain(image, obstacle_mask):\n",
        "    \"\"\"\n",
        "    Classify terrain into traversable and non-traversable areas\n",
        "\n",
        "    Args:\n",
        "        image: Original terrain image\n",
        "        obstacle_mask: Binary mask with obstacles\n",
        "    Returns:\n",
        "        Visualization with traversable areas marked\n",
        "    \"\"\"\n",
        "    # Create a copy of the input image\n",
        "    visualization = image.copy()\n",
        "\n",
        "    # Create a colored overlay for obstacles (red)\n",
        "    red_mask = np.zeros_like(image)\n",
        "    red_mask[obstacle_mask > 0] = [0, 0, 255]  # BGR format\n",
        "\n",
        "    # Create a colored overlay for safe areas (green)\n",
        "    green_mask = np.zeros_like(image)\n",
        "    green_mask[obstacle_mask == 0] = [0, 255, 0]  # BGR format\n",
        "\n",
        "    # Blend with original image\n",
        "    alpha = 0.3  # Transparency factor\n",
        "    visualization = cv2.addWeighted(visualization, 1, red_mask, alpha, 0)\n",
        "    visualization = cv2.addWeighted(visualization, 1, green_mask, alpha * 0.5, 0)\n",
        "\n",
        "    return visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU26SFhICHyo"
      },
      "source": [
        "Path Planning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tZB8bfm3CJR-"
      },
      "outputs": [],
      "source": [
        "def create_navigation_graph(obstacle_mask, grid_size=20):\n",
        "    \"\"\"\n",
        "    Create navigation graph from obstacle mask\n",
        "\n",
        "    Args:\n",
        "        obstacle_mask: Binary mask with obstacles\n",
        "        grid_size: Size of grid cells\n",
        "    Returns:\n",
        "        Graph representation and node coordinates\n",
        "    \"\"\"\n",
        "    height, width = obstacle_mask.shape\n",
        "\n",
        "    # Create grid\n",
        "    nodes = {}\n",
        "    node_coords = {}\n",
        "    node_id = 0\n",
        "\n",
        "    for y in range(0, height, grid_size):\n",
        "        for x in range(0, width, grid_size):\n",
        "            # Check if grid cell is mostly obstacle-free\n",
        "            cell = obstacle_mask[y:y+grid_size, x:x+grid_size]\n",
        "            if cell.size > 0 and np.mean(cell) < 127:  # Mostly traversable\n",
        "                nodes[node_id] = []\n",
        "                node_coords[node_id] = (x + grid_size//2, y + grid_size//2)\n",
        "                node_id += 1\n",
        "\n",
        "    # Connect neighboring nodes\n",
        "    for node in nodes:\n",
        "        x1, y1 = node_coords[node]\n",
        "        for other_node in nodes:\n",
        "            if node == other_node:\n",
        "                continue\n",
        "\n",
        "            x2, y2 = node_coords[other_node]\n",
        "            # Check if nodes are neighbors (within 1.5 * grid_size)\n",
        "            dist = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
        "            if dist < 1.5 * grid_size:\n",
        "                # Check if connection crosses obstacles\n",
        "                line_mask = np.zeros_like(obstacle_mask)\n",
        "                cv2.line(line_mask, (x1, y1), (x2, y2), 255, 1)\n",
        "                line_pixels = np.logical_and(line_mask > 0, obstacle_mask > 0)\n",
        "\n",
        "                if np.sum(line_pixels) < 0.3 * np.sum(line_mask > 0):\n",
        "                    # Connection is mostly obstacle-free\n",
        "                    nodes[node].append((other_node, dist))\n",
        "\n",
        "    return nodes, node_coords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fKkYUgK9CB_M"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "\n",
        "def a_star(graph, start, goal, node_coords):\n",
        "    \"\"\"\n",
        "    Find shortest path using A* algorithm\n",
        "\n",
        "    Args:\n",
        "        graph: Navigation graph\n",
        "        start: Start node ID\n",
        "        goal: Goal node ID\n",
        "        node_coords: Dictionary mapping node IDs to coordinates\n",
        "    Returns:\n",
        "        Path as list of node IDs and total distance\n",
        "    \"\"\"\n",
        "    # Helper function to calculate heuristic (Euclidean distance)\n",
        "    def heuristic(node):\n",
        "        x1, y1 = node_coords[node]\n",
        "        x2, y2 = node_coords[goal]\n",
        "        return np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
        "\n",
        "    # Priority queue for open nodes\n",
        "    open_set = [(0, start)]  # (f_score, node)\n",
        "\n",
        "    # For reconstructing the path\n",
        "    came_from = {}\n",
        "\n",
        "    # Cost from start to current node\n",
        "    g_score = {node: float('inf') for node in graph}\n",
        "    g_score[start] = 0\n",
        "\n",
        "    # Estimated total cost from start to goal through node\n",
        "    f_score = {node: float('inf') for node in graph}\n",
        "    f_score[start] = heuristic(start)\n",
        "\n",
        "    while open_set:\n",
        "        _, current = heapq.heappop(open_set)\n",
        "\n",
        "        if current == goal:\n",
        "            # Reconstruct path\n",
        "            path = [current]\n",
        "            while current in came_from:\n",
        "                current = came_from[current]\n",
        "                path.append(current)\n",
        "            path.reverse()\n",
        "\n",
        "            # Calculate total distance\n",
        "            total_distance = g_score[goal]\n",
        "\n",
        "            return path, total_distance\n",
        "\n",
        "        for neighbor, distance in graph[current]:\n",
        "            tentative_g = g_score[current] + distance\n",
        "\n",
        "            if tentative_g < g_score[neighbor]:\n",
        "                came_from[neighbor] = current\n",
        "                g_score[neighbor] = tentative_g\n",
        "                f_score[neighbor] = tentative_g + heuristic(neighbor)\n",
        "\n",
        "                # Add to open set if not already there\n",
        "                for item in open_set:\n",
        "                    if item[1] == neighbor:\n",
        "                        break\n",
        "                else:\n",
        "                    heapq.heappush(open_set, (f_score[neighbor], neighbor))\n",
        "\n",
        "    return None, float('inf')  # No path found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aQZMCsUuCPBC"
      },
      "outputs": [],
      "source": [
        "def visualize_path(image, path, node_coords):\n",
        "    \"\"\"\n",
        "    Draw the optimal path on terrain image\n",
        "\n",
        "    Args:\n",
        "        image: Terrain image\n",
        "        path: List of node IDs forming the path\n",
        "        node_coords: Dictionary mapping node IDs to coordinates\n",
        "    Returns:\n",
        "        Image with path visualized\n",
        "    \"\"\"\n",
        "    result = image.copy()\n",
        "\n",
        "    # Draw path\n",
        "    for i in range(len(path) - 1):\n",
        "        start = node_coords[path[i]]\n",
        "        end = node_coords[path[i+1]]\n",
        "        cv2.line(result, start, end, (0, 255, 255), 3)  # Yellow line\n",
        "\n",
        "    # Mark start and end points\n",
        "    cv2.circle(result, node_coords[path[0]], 10, (255, 0, 0), -1)  # Blue start\n",
        "    cv2.circle(result, node_coords[path[-1]], 10, (0, 0, 255), -1)  # Red end\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dsIUBT4xCUAU"
      },
      "outputs": [],
      "source": [
        "def calculate_path_distance(path, node_coords):\n",
        "    \"\"\"\n",
        "    Calculate total distance along path\n",
        "\n",
        "    Args:\n",
        "        path: List of node IDs forming the path\n",
        "        node_coords: Dictionary mapping node IDs to coordinates\n",
        "    Returns:\n",
        "        Total distance in pixels\n",
        "    \"\"\"\n",
        "    total_distance = 0\n",
        "\n",
        "    for i in range(len(path) - 1):\n",
        "        x1, y1 = node_coords[path[i]]\n",
        "        x2, y2 = node_coords[path[i+1]]\n",
        "        segment_distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
        "        total_distance += segment_distance\n",
        "\n",
        "    return total_distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKnhyrGG-VM5"
      },
      "outputs": [],
      "source": [
        "def process_drone_imagery(video_path, start_coords, end_coords):\n",
        "    \"\"\"\n",
        "    Full processing pipeline from drone video to optimal path\n",
        "\n",
        "    Args:\n",
        "        video_path: Path to drone video\n",
        "        start_coords: Starting coordinates (x, y)\n",
        "        end_coords: Ending coordinates (x, y)\n",
        "    Returns:\n",
        "        Final visualization with path\n",
        "    \"\"\"\n",
        "    # 1. Extract frames\n",
        "    frames = []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if len(frames) % 10 == 0:  # Take every 10th frame\n",
        "            frames.append(frame)\n",
        "    cap.release()\n",
        "\n",
        "    # 2. Preprocess frames\n",
        "    processed_frames = [preprocess_image(frame) for frame in frames]\n",
        "\n",
        "    # 3. Stitch images\n",
        "    terrain_map = stitch_images_custom(processed_frames)\n",
        "\n",
        "    # 4. Detect obstacles\n",
        "    obstacle_mask = detect_obstacles(terrain_map)\n",
        "\n",
        "    # 5. Create navigation graph\n",
        "    graph, node_coords = create_navigation_graph(obstacle_mask)\n",
        "\n",
        "    # 6. Find closest nodes to start and end coordinates\n",
        "    start_node = min(node_coords.keys(),\n",
        "                     key=lambda n: ((node_coords[n][0] - start_coords[0])**2 +\n",
        "                                    (node_coords[n][1] - start_coords[1])**2))\n",
        "    end_node = min(node_coords.keys(),\n",
        "                   key=lambda n: ((node_coords[n][0] - end_coords[0])**2 +\n",
        "                                  (node_coords[n][1] - end_coords[1])**2))\n",
        "\n",
        "    # 7. Find optimal path\n",
        "    path, distance = a_star(graph, start_node, end_node, node_coords)\n",
        "\n",
        "    # 8. Visualize results\n",
        "    terrain_with_obstacles = classify_terrain(terrain_map, obstacle_mask)\n",
        "    final_visualization = visualize_path(terrain_with_obstacles, path, node_coords)\n",
        "\n",
        "    # 9. Add distance information\n",
        "    text = f\"Optimal path distance: {distance:.2f} units\"\n",
        "    cv2.putText(final_visualization, text, (20, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    return final_visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ss_G8CGgYGiU"
      },
      "outputs": [],
      "source": [
        "process_drone_imagery('/content/a-flight-over-the-woods-SBV-337898150-preview.mp4',(100,100),(200,200))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm1oreCxYKeB"
      },
      "source": [
        "Extracting frames from video...\n",
        "\n",
        "Extracted 166 frames\n",
        "\n",
        "First frame shape: (1080, 1920, 3), dtype: uint8\n",
        "\n",
        "Stitching images...\n",
        "\n",
        "Optimal path distance: 564.4m"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
